{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad406e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_loading import balance_videos_list\n",
    "from extract_keypoints import KeypointInterpolator\n",
    "\n",
    "folder_path = r'10 class 28 actor (different size)'\n",
    "num_labels = balance_videos_list(folder_path)\n",
    "\n",
    "interpolator = KeypointInterpolator(num_labels, frames=80)\n",
    "interpolator.run()\n",
    "\n",
    "a = np.load(f'vsl{num_labels}_data_preprocess.npy')\n",
    "b = np.load(f'vsl{num_labels}_label_preprocess.npy')\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(train_data, keypoint_data, label_data, num_labels, k_folds, destination_folder=\"numpy_files\"):\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "    actors = train_data['actor'].unique()\n",
    "    print(f\"Number of actors: {len(actors)}\")\n",
    "    print('-----------------------------------------------------')\n",
    "\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    actor_to_indices = {actor: train_data.index[train_data['actor'] == actor].tolist() for actor in actors}\n",
    "    folds = [[] for _ in range(k_folds)]\n",
    "\n",
    "    for fold, (train_actors, test_actors) in enumerate(kf.split(actors)):\n",
    "        train_actors = actors[train_actors]\n",
    "        test_actors = actors[test_actors]\n",
    "\n",
    "        for actor in test_actors:\n",
    "            folds[fold].extend(actor_to_indices[actor])\n",
    "\n",
    "        tqdm.write(f\"Fold {fold+1}: {len(folds[fold])} test samples\")\n",
    "\n",
    "    # Iterate over each fold to create train-test splits\n",
    "    for fold in range(k_folds):\n",
    "        test_indices = folds[fold]\n",
    "        train_indices = [idx for f in range(k_folds) if f != fold for idx in folds[f]]\n",
    "\n",
    "        X_train, X_test = keypoint_data[train_indices], keypoint_data[test_indices]\n",
    "        y_train = np.array(label_data[train_indices], dtype=np.int64)\n",
    "        y_test = np.array(label_data[test_indices], dtype=np.int64)\n",
    "\n",
    "        np.save(os.path.join(destination_folder, f'vsl{num_labels}_data_fold{fold+1}_train.npy'), X_train)\n",
    "        np.save(os.path.join(destination_folder, f'vsl{num_labels}_label_fold{fold+1}_train.npy'), y_train)\n",
    "        np.save(os.path.join(destination_folder, f'vsl{num_labels}_data_fold{fold+1}_test.npy'), X_test)\n",
    "        np.save(os.path.join(destination_folder, f'vsl{num_labels}_label_fold{fold+1}_test.npy'), y_test)\n",
    "\n",
    "        tqdm.write(f\"Processed and saved vsl{num_labels} fold {fold+1} successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file_path = f\"vsl{num_labels}_interpolated_keypoints.csv\"\n",
    "    train_data = pd.read_csv(input_file_path)\n",
    "\n",
    "    keypoint_data = np.load(f'vsl{num_labels}_data_preprocess.npy')\n",
    "    label_data = np.load(f'vsl{num_labels}_label_preprocess.npy')\n",
    "\n",
    "    num_labels = len(np.unique(label_data))\n",
    "\n",
    "    k_folds = 10\n",
    "    k_fold_cross_validation(train_data, keypoint_data, label_data, num_labels, k_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d07b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from feeder import FeederINCLUDE\n",
    "from aagcn import Model\n",
    "from augumentation import Rotate, Compose\n",
    "from pytorch_lightning.utilities.migration import pl_legacy_patch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k_folds = 10\n",
    "    config = {'batch_size': 128, 'learning_rate': 0.0137296, 'weight_decay': 0.000150403}\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    best_fold = -1\n",
    "\n",
    "    for fold in range(k_folds):\n",
    "        print(f\"Starting fold {fold + 1}/{k_folds}\")\n",
    "        train_data_path = os.path.join(\"numpy_files\", f'vsl{num_labels}_data_fold{fold+1}_train.npy')\n",
    "        train_label_path = os.path.join(\"numpy_files\", f'vsl{num_labels}_label_fold{fold+1}_train.npy')\n",
    "        val_data_path = os.path.join(\"numpy_files\", f'vsl{num_labels}_data_fold{fold+1}_test.npy')\n",
    "        val_label_path = os.path.join(\"numpy_files\", f'vsl{num_labels}_label_fold{fold+1}_test.npy')\n",
    "\n",
    "        transforms = Compose([\n",
    "            Rotate(15, 80, 25, (0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        train_dataset = FeederINCLUDE(\n",
    "            data_path=train_data_path,\n",
    "            label_path=train_label_path,\n",
    "            transform=transforms\n",
    "        )\n",
    "        val_dataset = FeederINCLUDE(\n",
    "            data_path=val_data_path,\n",
    "            label_path=val_label_path\n",
    "        )\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "        model = Model(num_class=num_labels, num_point=46, num_person=1, in_channels=2,\n",
    "                      graph_args={\"layout\": \"mediapipe_two_hand\", \"strategy\": \"spatial\"},\n",
    "                      learning_rate=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "\n",
    "        # Path pre-trained checkpoint file\n",
    "        checkpoint_path = \"autsl_vsl199-aagcn-fold=7-v1.ckpt\"\n",
    "\n",
    "        with pl_legacy_patch():\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        filtered_state_dict = {k: v for k, v in state_dict.items() if not k.startswith('fc.')}\n",
    "        model.load_state_dict(filtered_state_dict, strict=False)\n",
    "\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(\n",
    "                dirpath=\"checkpoints\",\n",
    "                monitor=\"valid_accuracy\",\n",
    "                mode=\"max\",\n",
    "                every_n_epochs=1,\n",
    "                filename=f'autsl_vsl{num_labels}-aagcn-fold={fold+1}'\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        trainer = pl.Trainer(max_epochs=100, accelerator=\"auto\", check_val_every_n_epoch=1,\n",
    "                             devices=1, callbacks=callbacks)\n",
    "\n",
    "        trainer.fit(model, train_dataloader, val_dataloader)\n",
    "        val_accuracy = trainer.callback_metrics['valid_accuracy'].item()\n",
    "        print(f\"Fold {fold + 1} finished with validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_fold = fold + 1\n",
    "\n",
    "    print(f\"The highest validation accuracy achieved is {best_accuracy:.4f} from fold {best_fold}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae352300",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The highest validation accuracy achieved of autsl vsl{num_labels} is {best_accuracy:.4f} from fold {best_fold}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
